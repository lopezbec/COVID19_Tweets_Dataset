{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatically_Hydrate_TweetsIDs_COVID19_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RDzd7FUKFviv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQiik2HFUtqL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<center><b>© 2020. Content is made available under the CC-BY-NC-ND 4.0 license. Christian Lopez, lopezbec@lafayette.edu/  Malolan Vasu, vasum@lafayette.edu <b><center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMczOoPVH6e"
      },
      "source": [
        "**UPDATED ON 10-18-2020**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmFBUngZaxt7"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lopezbec/COVID19_Tweets_Dataset/blob/master/Automatically_Hydrate_TweetsIDs_COVID19_v2.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrI81Xn6wh0d"
      },
      "source": [
        "# **Notebook to automatically \"hydrate\" tweets-ID**\n",
        "\n",
        "This notebook will allow you to automatically hydrate the tweets-ID from our [COVID19_Tweets_dataset GitHub repository](https://github.com/lopezbec/COVID19_Tweets_Dataset).\n",
        "\n",
        "\n",
        "You can run this notebook directly on the cloud using Google Colab [(see how to tutorials)]( https://colab.research.google.com/notebooks/welcome.ipynb#scrollTo=xitplqMNk_Hc) and Google Drive.\n",
        "\n",
        "In order to hydrate the tweet-IDs using [TWARC](https://github.com/DocNow/twarc) you need to create a [Twitter Developer Account]( https://developer.twitter.com/en/apply-for-access).\n",
        "\n",
        "First run the Initialization block to set up the required libraries. Then, run the Configuration block and choose your required configuration for tweet IDs to hydrate (dates needed, keywords needed). Finally, run the Hydrate block.  In the case that the code unexpectedly stops in the hydrate phase, you only need to run Initialization and Hydration. You aren't required to run configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbVmAxxGHUjO"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-Zr5kB6wknZ"
      },
      "source": [
        "### Mount Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHzFzMoOV0tu"
      },
      "source": [
        "The code will clone part the repository and place it in your Google drive. Also, the notebook will place all the hydrated tweets in your Google Drive. Here you need to type where in your Google Drive you would like the information stored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeimRLrjwpRr",
        "cellView": "form",
        "outputId": "3d69def8-184f-4951-fedb-75fe707e7491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive \n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/gdrive')\n",
        "working_directory = 'My Drive/COVID19_Tweets' #@param {type:\"string\"}\n",
        "wd=\"/content/gdrive/\"+working_directory\n",
        "os.chdir(wd)\n",
        "\n",
        "dirpath = os.getcwd()\n",
        "print(\"current directory is : \" + dirpath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "current directory is : /content/gdrive/My Drive/COVID19_Tweets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDzd7FUKFviv"
      },
      "source": [
        "### Install twarc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvHm-ggFubK"
      },
      "source": [
        "%pip install twarc\n",
        "%pip install jsonlines\n",
        "%pip install wget\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gBPP8oJGDqM",
        "outputId": "e45a317e-7245-4890-b2c5-b45c2174462f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Check if TWARC was installed correctly on the Virtual Machine\n",
        "%pip show twarc\n",
        "%pip show jsonlines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: twarc\n",
            "Version: 1.10.2\n",
            "Summary: Archive tweets from the command line\n",
            "Home-page: https://github.com/docnow/twarc\n",
            "Author: Ed Summers\n",
            "Author-email: ehs@pobox.com\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: requests-oauthlib, python-dateutil, pytest\n",
            "Required-by: \n",
            "Name: jsonlines\n",
            "Version: 1.2.0\n",
            "Summary: Library with helpers for the jsonlines file format\n",
            "Home-page: https://github.com/wbolster/jsonlines\n",
            "Author: Wouter Bolsterlee\n",
            "Author-email: wouter@bolsterl.ee\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: six\n",
            "Required-by: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEsz47hdFHtW"
      },
      "source": [
        "### Twitter API Keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et0_5DEEFNpW",
        "cellView": "form"
      },
      "source": [
        "#@title Insert API Keys here { run : \"auto\"}\n",
        "from twarc import Twarc\n",
        "\n",
        "# These keys are received after applying for a twitter developer account\n",
        "\n",
        "consumer_key = \"\" #@param {type:\"string\"}\n",
        "consumer_secret = \"\" #@param {type:\"string\"}\n",
        "access_token = \"\" #@param {type:\"string\"}\n",
        "access_token_secret = \"\" #@param {type:\"string\"}\n",
        "\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyS66qo29K_g"
      },
      "source": [
        "### Download Github Files onto Drive for given dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiHM582ReTh"
      },
      "source": [
        "You need to frist indicate the date range of file you would like to hydrate. Rememeber that the Start_date cannot be before 2020-01-22. If a incorrect end date is selected it will be not considered.  At the end you will see how many files you are requesting to download \n",
        "\n",
        "(it is assumed you want all hours from a given day, if you dont want some hour, you will need to deleted the hours you wont want).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeLOiUghTpKc",
        "cellView": "form",
        "outputId": "4c62b9f6-1d07-41bc-9676-610473c89127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#@title Date fields\n",
        "import pandas as pd\n",
        "Start_date = '2020-01-22' #@param {type:\"date\"}\n",
        "#@title Date fields\n",
        "End_date = '2020-01-23' #@param {type:\"date\"}\n",
        "\n",
        "\n",
        "\n",
        "datelist = pd.date_range(Start_date, End_date).tolist()\n",
        "number_files=0\n",
        "for date in datelist:\n",
        "  for h in ['00','01', '02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']:\n",
        "    number_files=number_files+1\n",
        "\n",
        "print(\"You have requested to download a total of \"+ str(number_files) + ' files \\n The more files you download at once the longer it will take to upload to your Drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have requested to download a total of 48 files \n",
            " The more files you download at once the longer it will take to upload to your Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VtnuqvTgIJO"
      },
      "source": [
        "The code below will create a new directory `Summary_Details_files` and save all the `.csv. files from the reposiory that were requested on that directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPbChi1mbVHv"
      },
      "source": [
        "\n",
        "from datetime import datetime\n",
        "import wget\n",
        "\n",
        "path = os.path.join(wd, \"Summary_Details_files\") \n",
        "if not os.path.exists('./Summary_Details_files'):\n",
        "  try:\n",
        "    os.makedirs(path)\n",
        "    os.chdir('Summary_Details_files')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "datelist = pd.date_range(Start_date, End_date).tolist()\n",
        "files_list=[]\n",
        "for date in datelist:\n",
        "  day=date.strftime(\"%Y_%m_%d\")\n",
        "  p1=\"https://raw.githubusercontent.com/lopezbec/COVID19_Tweets_Dataset/master/Summary_Details/\"\n",
        "  m=day[0:7]\n",
        "  for h in ['00','01', '02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23']:\n",
        "    file=p1+m+\"/\"+day+\"_\"+str(h)+\"_Summary_Details.csv\"\n",
        "    wget.download(file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASdYyTqI9RUG"
      },
      "source": [
        "# Choose Settings Tweets_IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo52kGhpk69s"
      },
      "source": [
        "This are all the files you requested:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLREJkIRjvDh",
        "outputId": "ffe0663d-6df3-431e-bf19-017dc7b73ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd \n",
        "\n",
        "Summary_Details=pd.DataFrame() \n",
        "directory =  os.getcwd()\n",
        "for root,dirs,files in os.walk(directory):\n",
        "  for file in files:\n",
        "    if file.endswith(\".csv\"):\n",
        "      data = pd.read_csv(file) \n",
        "      frames = [Summary_Details, data]\n",
        "      Summary_Details = pd.concat(frames)\n",
        "Summary_Details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Geolocation_coordinate</th>\n",
              "      <th>RT</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Country</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1219771665762213888</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wed Jan 22 00:00:02 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1219771981056200704</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>2402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wed Jan 22 00:01:17 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1219772064296361986</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wed Jan 22 00:01:37 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1219772159603527683</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>261</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wed Jan 22 00:01:59 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1219772340558614528</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wed Jan 22 00:02:42 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12613</th>\n",
              "      <td>1220493297120161796</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thu Jan 23 23:47:32 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12614</th>\n",
              "      <td>1220493298332139520</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>2833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thu Jan 23 23:47:32 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12615</th>\n",
              "      <td>1220493302459293698</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thu Jan 23 23:47:33 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12616</th>\n",
              "      <td>1220493302564184064</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thu Jan 23 23:47:33 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12617</th>\n",
              "      <td>1220493312936812545</td>\n",
              "      <td>en</td>\n",
              "      <td>NO</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Thu Jan 23 23:47:36 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>240023 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tweet_ID Language  ... Country                    Date Created\n",
              "0      1219771665762213888       en  ...     NaN  Wed Jan 22 00:00:02 +0000 2020\n",
              "1      1219771981056200704       en  ...     NaN  Wed Jan 22 00:01:17 +0000 2020\n",
              "2      1219772064296361986       en  ...     NaN  Wed Jan 22 00:01:37 +0000 2020\n",
              "3      1219772159603527683       en  ...     NaN  Wed Jan 22 00:01:59 +0000 2020\n",
              "4      1219772340558614528       en  ...     NaN  Wed Jan 22 00:02:42 +0000 2020\n",
              "...                    ...      ...  ...     ...                             ...\n",
              "12613  1220493297120161796       en  ...     NaN  Thu Jan 23 23:47:32 +0000 2020\n",
              "12614  1220493298332139520       en  ...     NaN  Thu Jan 23 23:47:32 +0000 2020\n",
              "12615  1220493302459293698       en  ...     NaN  Thu Jan 23 23:47:33 +0000 2020\n",
              "12616  1220493302564184064       en  ...     NaN  Thu Jan 23 23:47:33 +0000 2020\n",
              "12617  1220493312936812545       en  ...     NaN  Thu Jan 23 23:47:36 +0000 2020\n",
              "\n",
              "[240023 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0CfU-SUlUIp"
      },
      "source": [
        "### Filter Tweets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fj9ydtn9aIL"
      },
      "source": [
        "You can filter the tweets by:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGdsBbsHxrcG",
        "cellView": "form",
        "outputId": "c3404c51-4736-4422-9f24-7674b00ee3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "\n",
        "Just_English_Tweets= True #@param {type:\"boolean\"}\n",
        "Just_with_Geolocation_information = True #@param {type:\"boolean\"}\n",
        "Just_Original_tweets = True #@param {type:\"boolean\"}\n",
        "Minimun_No_Likes = 3 #@param {type:\"number\"}\n",
        "Minimun_No_Retweets =  0#@param {type:\"number\"}\n",
        "\n",
        "Summary_Details2=Summary_Details\n",
        "if(Just_English_Tweets):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['Language']=='en']\n",
        "if(Just_with_Geolocation_information):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['Geolocation_coordinate']=='YES']\n",
        "if(Just_Original_tweets):\n",
        "  Summary_Details2=Summary_Details2[ Summary_Details2['RT']=='NO']\n",
        "\n",
        "\n",
        "Summary_Details2=Summary_Details2[ Summary_Details2['Likes']>=Minimun_No_Likes]\n",
        "Summary_Details2=Summary_Details2[ Summary_Details2['Retweets']>=Minimun_No_Retweets]\n",
        "\n",
        "Summary_Details2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_ID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Geolocation_coordinate</th>\n",
              "      <th>RT</th>\n",
              "      <th>Likes</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Country</th>\n",
              "      <th>Date Created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1220150539146514432</td>\n",
              "      <td>en</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>TH</td>\n",
              "      <td>Thu Jan 23 01:05:32 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>1220245868286181376</td>\n",
              "      <td>en</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>NZ</td>\n",
              "      <td>Thu Jan 23 07:24:20 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1332</th>\n",
              "      <td>1220265816030973952</td>\n",
              "      <td>en</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>CN</td>\n",
              "      <td>Thu Jan 23 08:43:36 +0000 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3826</th>\n",
              "      <td>1220487038786580481</td>\n",
              "      <td>en</td>\n",
              "      <td>YES</td>\n",
              "      <td>NO</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>HK</td>\n",
              "      <td>Thu Jan 23 23:22:40 +0000 2020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Tweet_ID Language  ... Country                    Date Created\n",
              "199   1220150539146514432       en  ...      TH  Thu Jan 23 01:05:32 +0000 2020\n",
              "717   1220245868286181376       en  ...      NZ  Thu Jan 23 07:24:20 +0000 2020\n",
              "1332  1220265816030973952       en  ...      CN  Thu Jan 23 08:43:36 +0000 2020\n",
              "3826  1220487038786580481       en  ...      HK  Thu Jan 23 23:22:40 +0000 2020\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81sHrmZtID9"
      },
      "source": [
        "For more personalized filtering you can modify the pandas dataframe directly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BDEuBH7LPTn"
      },
      "source": [
        "### Save configuration into a file\n",
        "All the IDs are read into a single set in the previous code block using the specified configuration. The ID Output file stores all the IDs in a single file so that the configuration blocks don't have to be run again. In case the program unexpectedly stops, you can just run the code for Initialization and then the code for Hydration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4EfPTrnLO0c",
        "cellView": "form"
      },
      "source": [
        "#@title Enter ID output file {run: \"auto\"}\n",
        "os.chdir(wd)\n",
        "final_tweet_ids_filename = \"final_ids.txt\" #@param {type: \"string\"}\n",
        "# The set of IDs is stored in this file.\n",
        "with open(final_tweet_ids_filename, \"w+\") as f:\n",
        "    for id in Summary_Details2['Tweet_ID']:\n",
        "        f.write('%s\\n' % id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxFa0jOTKbBw"
      },
      "source": [
        "# Hydrate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBBH-a4WK1JM"
      },
      "source": [
        "### Set up output file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U74uUnemI6h9"
      },
      "source": [
        "The final_tweet_ids_filename should be exactly the same as the ID output file from the Configuration block. If this file does not exist in the working directory, you have to re-run the Configuration block.\n",
        "\n",
        "Please also keep the output_filename the same in case the code is halted. That way, tweets already hydrated aren't re-hydrated for no reason. \n",
        "\n",
        "Also, please do not remove the .txt file created after running the Hydrate block until all the data is converted to a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ATxyEfSLBK1",
        "cellView": "form"
      },
      "source": [
        "#@title Set up Directory { run: \"auto\"}\n",
        "final_tweet_ids_filename = \"final_ids.txt\" #@param {type: \"string\"}\n",
        "output_filename = \"output.csv\" #@param {type: \"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG9cS-aoW0Wy"
      },
      "source": [
        "The time for this code will depend on how many tweets you want to “hydrate”. Also, be advise of the Tweet API limit, the code will “go to sleep” once the limit is reach and automatically continue. \n",
        "You can leave this code running in Google Colab for a max of 12hrs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwYd7m58WR3",
        "outputId": "fc18b6da-9a7e-4896-e6f8-d15b97f8a669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import jsonlines, json\n",
        "# Stores hydrated tweets here as jsonl objects\n",
        "# Contains one json object per line\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "ids = []\n",
        "with open(final_tweet_ids_filename, \"r\") as ids_file:\n",
        "    ids = ids_file.read().split()\n",
        "hydrated_tweets = []\n",
        "ids_to_hydrate = set(ids)\n",
        "\n",
        "# Looks at the output file for already hydrated tweets\n",
        "if os.path.isfile(output_json_filename):\n",
        "    with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "        for i in reader.iter(type=dict, skip_invalid=True):\n",
        "            # These tweets have already been hydrated. So remove them from ids_to_hydrate\n",
        "            hydrated_tweets.append(i)\n",
        "            ids_to_hydrate.remove(i[\"id_str\"])\n",
        "print(\"Total IDs: \" + str(len(ids)) + \", IDs to hydrate: \" + str(len(ids_to_hydrate)))\n",
        "print(\"Hydrated: \" + str(len(hydrated_tweets)))\n",
        "\n",
        "count = len(hydrated_tweets)\n",
        "start_index = count # The index from where tweets haven't been saved to the output_json_file\n",
        "# Stores hydrated tweets to output_json_file every num_save iterations.\n",
        "num_save  = 1000\n",
        "\n",
        "# Now, use twarc and start hydrating\n",
        "for tweet in t.hydrate(ids_to_hydrate):\n",
        "    hydrated_tweets.append(tweet)\n",
        "    count += 1\n",
        "    # If num_save iterations have passed,\n",
        "    if (count % num_save) == 0:\n",
        "        # Open the output file\n",
        "        # NOTE: Even if the code stops during IO, only tweets from the current iteration are lost.\n",
        "        # Older tweets are preserved as the file is written in append mode.\n",
        "        with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "            print(\"Started IO\")\n",
        "            # Now write the tweets from start_index. The other tweets don't have to be written\n",
        "            # as they were already written in a previous iteration or run.\n",
        "            for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "                writer.write(hydrated_tweet)\n",
        "            print(\"Finished IO\")\n",
        "        print(\"Saved \" + str(count) + \" hydrated tweets.\")\n",
        "        # Now, since everything has been written. Reset start_index\n",
        "        start_index = count\n",
        "# There might be tweets unwritten in the last iteration if the count is not a multiple of num_tweets.\n",
        "# In that case, just write out the remainder of tweets.\n",
        "if count != start_index:\n",
        "    print(\"Here with start_index\", start_index)\n",
        "    with jsonlines.open(output_json_filename, \"a\") as writer:\n",
        "        for hydrated_tweet in hydrated_tweets[start_index:]:\n",
        "           writer.write(hydrated_tweet)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total IDs: 4, IDs to hydrate: 4\n",
            "Hydrated: 0\n",
            "Here with start_index 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6O-KWKnbcGt"
      },
      "source": [
        "## Convert JSONL to CSV\n",
        "Data is stored in  output_json_file from the previous code block. This now converts the jsonl .txt file into a csv file. Note that the column names required is stored as a list in the code.\n",
        "\n",
        "Note that a few of the columns are actually json objects (for example, user or entities). You will have to clean these objects into 1D data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x68cvh5AJCD"
      },
      "source": [
        "# Convert jsonl to csv\n",
        "import csv, jsonlines\n",
        "output_json_filename = output_filename[:output_filename.index(\".\")] + \".txt\"\n",
        "# These are the column name that are selected to be stored in the csv\n",
        "keyset = [\"created_at\", \"id\", \"id_str\", \"full_text\", \"source\", \"truncated\", \"in_reply_to_status_id\",\n",
        "          \"in_reply_to_status_id_str\", \"in_reply_to_user_id\", \"in_reply_to_user_id_str\", \n",
        "          \"in_reply_to_screen_name\", \"user\", \"coordinates\", \"place\", \"quoted_status_id\",\n",
        "          \"quoted_status_id_str\", \"is_quote_status\", \"quoted_status\", \"retweeted_status\", \n",
        "          \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\", \"entities\", \n",
        "          \"extended_entities\", \"favorited\", \"retweeted\", \"possibly_sensitive\", \"filter_level\", \n",
        "          \"lang\", \"matching_rules\", \"current_user_retweet\", \"scopes\", \"withheld_copyright\", \n",
        "          \"withheld_in_countries\", \"withheld_scope\", \"geo\", \"contributors\", \"display_text_range\",\n",
        "          \"quoted_status_permalink\"]\n",
        "hydrated_tweets = []\n",
        "# Reads the current tweets\n",
        "with jsonlines.open(output_json_filename, \"r\") as reader:\n",
        "    for i in reader.iter(type=dict, skip_invalid=True):\n",
        "        hydrated_tweets.append(i)\n",
        "# Writes them out\n",
        "with  open(output_filename, \"w+\") as output_file:\n",
        "    d = csv.DictWriter(output_file, keyset)\n",
        "    d.writeheader()\n",
        "    d.writerows(hydrated_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utvrm8g7NHNs"
      },
      "source": [
        "Your data is now stored in output_filename. If you want to re-run  this notebook, please copy output_filename file to a different directory."
      ]
    }
  ]
}